{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Langchain?\n",
    "- Langchain is a software library designed to simplify the integration of large language models (LLMs) into applications by providing modular components.\n",
    "- It enables developers to build, test, and deploy NLP and AI applications more efficiently, by offering tools and templates for tasks like chatbots, document processing, and information retrieval.\n",
    "- The library supports various functionalities such as embedding models, document loaders, vector stores, and more, facilitating a comprehensive approach to building AI-driven solutions.\n",
    "\n",
    "![](src/imageeee.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langchain's library offers a variety of \"components\" that facilitate the development of NLP/LLM-related products and software. These components include:\n",
    "\n",
    "- Chat Models\n",
    "- Large Language Models (LLMs)\n",
    "- Embedding Models\n",
    "- Document Loaders\n",
    "- Document Transformers\n",
    "- Vector Stores\n",
    "- Retrievers\n",
    "- Tools\n",
    "\n",
    "...and much more.\n",
    "\n",
    "In this presentation, we'll explore some implementations of these components. We will conclude with a demonstration of a small-scale notebook-based RAG (Retrieve and Generate) prototype, showcasing how these elements can be integrated and function cohesively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textbook RAG Demonstration Using Langchain\n",
    "### Part 1: Loading, Processing, & Uploading Our Documents\n",
    "\n",
    "Understanding any high-level framework always begins by looking at and understanding the imports you'll be using.\n",
    "\n",
    "Looking at our imports we see that we first import our 'Document Loader/Transformer' components, which in this case is `PyPDFLoader` & `RecurseiveCharacterSplitter` respectively.\n",
    "\n",
    "Next, we import our \"Embedding Model & Vector Store\" components, which in this case is the `HuggingFaceEmbeddings` & `PineconeVectorStore` respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    \n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's setup our PDF Loader, passing through the path for the textbook, and our Text Splitter, passing through our desired text splitting settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = PyPDFLoader(\"Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50, length_function=len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now running our PDF Loader & Splitter with the convenient `load_and_split` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = pdf_loader.load_and_split(text_splitter=text_splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting our chunks, we can see that each chunk is stored in a list, with a `page_content` component containing the actual text of the chunk, and also a `metadata` component which stores a dictionary of metadata for each chunk, including the name of the original source of the chunk and also the page from which it came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Chapman & Hall/CRC \\nMachine Learning & Pattern Recognition SeriesChapman & Hall/CRC \\nMachine Learning & Pattern Recognition Series\\nMachine Learning MACHINE \\nLEARNING\\nAn Algorithmic Perspective\\nSecond Edition\\nMarsland\\nStephen Marsland\\n• Access online or download to your smartphone, tablet or PC/Mac\\n• Search the full text of this and other titles you own\\n• Make and share notes and highlights\\n• Copy and paste text and figures for use in your own documents', metadata={'source': 'Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf', 'page': 0}),\n",
       " Document(page_content='• Customize your view by changing font size and layoutWITH VITALSOURCE®\\nEBOOKsecond editionMachine Learning: An Algorithmic Perspective, Second Edition  helps you understand \\nthe algorithms of machine learning. It puts you on a path toward mastering the relevant \\nmathematics and statistics as well as the necessary programming and experimentation.\\nNew to the Second Edition\\n•  Two new chapters on deep belief networks and Gaussian processes', metadata={'source': 'Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf', 'page': 0}),\n",
       " Document(page_content='•  Reorganization of the chapters to make a more natural flow of content\\n•  Revision of the support vector machine material, including a simple implementation for \\nexperiments\\n•  New material on random forests, the perceptron convergence theorem, accuracy \\nmethods, and conjugate gradient optimization for the multi-layer perceptron\\n•  Additional discussions of the Kalman and particle filters\\n•  Improved code, including better use of naming conventions in Python', metadata={'source': 'Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf', 'page': 0}),\n",
       " Document(page_content='The text strongly encourages you to practice with the code. Each chapter includes detailed \\nexamples along with further reading and problems. All of the Python code used to create the \\nexamples is available on the author’s website. \\nFeatures\\n•  Reflects recent developments in machine learning, including the rise of deep belief \\nnetworks\\n•  Presents the necessary preliminaries, including basic probability and statistics\\n•  Discusses supervised learning using neural networks', metadata={'source': 'Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf', 'page': 0}),\n",
       " Document(page_content='•  Covers dimensionality reduction, the EM algorithm, nearest neighbor methods, optimal \\ndecision boundaries, kernel methods, and optimization\\n•  Describes evolutionary learning, reinforcement learning, tree-based learners, and \\nmethods to combine the predictions of many learners\\n•  Examines the importance of unsupervised learning, with a focus on the self-organizing \\nfeature map \\n•  Explores modern, statistically based approaches to machine learning\\nK18981\\nwww.crcpress.com\\nMachine Learning', metadata={'source': 'Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf', 'page': 0})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, we can also inspect the length of the `chunks` list and see if it makes sense, and in this case it does, especially since we set our chunk size to 500 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2285"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set up two variables, the `embedding_model`and our `textbook_vector_store`, these are generally set up as global variables as many different parts of your codebase will use them.\n",
    "\n",
    "We set the `embedding_model` to a `HuggingFaceEmbeddings` object, and our `textbook_vector_store` to a `PineconeVectorStore` object, using the `from_existing_index` method, in which we can pass through our embedding model, in addition to the index name, which we set to the name of our Pinecone index which we have set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings()\n",
    "textbook_vector_store = PineconeVectorStore.from_existing_index(embedding=embedding_model, index_name=\"textbook-vector-store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now parse both the text and metadata component of each chunk, parsing each of these components to their own list, taking special attention to parse the metadata as a dictionary as Pinecone expects metadata to be formatted that way as we'll see shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [chunk.page_content for chunk in chunks]\n",
    "metadatas = [{'page': chunk.metadata['page'] + 1, 'document': chunk.metadata['source']} for chunk in chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as we would expect, when we look within the `texts` list, we see the text component of the chunks. And ditto for the our `metadatas` list, where we see the metadata, including the page number & source file name for that particular chunk, formatted as a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chapman & Hall/CRC \\nMachine Learning & Pattern Recognition SeriesChapman & Hall/CRC \\nMachine Learning & Pattern Recognition Series\\nMachine Learning MACHINE \\nLEARNING\\nAn Algorithmic Perspective\\nSecond Edition\\nMarsland\\nStephen Marsland\\n• Access online or download to your smartphone, tablet or PC/Mac\\n• Search the full text of this and other titles you own\\n• Make and share notes and highlights\\n• Copy and paste text and figures for use in your own documents',\n",
       " '• Customize your view by changing font size and layoutWITH VITALSOURCE®\\nEBOOKsecond editionMachine Learning: An Algorithmic Perspective, Second Edition  helps you understand \\nthe algorithms of machine learning. It puts you on a path toward mastering the relevant \\nmathematics and statistics as well as the necessary programming and experimentation.\\nNew to the Second Edition\\n•  Two new chapters on deep belief networks and Gaussian processes',\n",
       " '•  Reorganization of the chapters to make a more natural flow of content\\n•  Revision of the support vector machine material, including a simple implementation for \\nexperiments\\n•  New material on random forests, the perceptron convergence theorem, accuracy \\nmethods, and conjugate gradient optimization for the multi-layer perceptron\\n•  Additional discussions of the Kalman and particle filters\\n•  Improved code, including better use of naming conventions in Python',\n",
       " 'The text strongly encourages you to practice with the code. Each chapter includes detailed \\nexamples along with further reading and problems. All of the Python code used to create the \\nexamples is available on the author’s website. \\nFeatures\\n•  Reflects recent developments in machine learning, including the rise of deep belief \\nnetworks\\n•  Presents the necessary preliminaries, including basic probability and statistics\\n•  Discusses supervised learning using neural networks',\n",
       " '•  Covers dimensionality reduction, the EM algorithm, nearest neighbor methods, optimal \\ndecision boundaries, kernel methods, and optimization\\n•  Describes evolutionary learning, reinforcement learning, tree-based learners, and \\nmethods to combine the predictions of many learners\\n•  Examines the importance of unsupervised learning, with a focus on the self-organizing \\nfeature map \\n•  Explores modern, statistically based approaches to machine learning\\nK18981\\nwww.crcpress.com\\nMachine Learning']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'page': 1,\n",
       "  'document': 'Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf'},\n",
       " {'page': 1,\n",
       "  'document': 'Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf'},\n",
       " {'page': 1,\n",
       "  'document': 'Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf'},\n",
       " {'page': 1,\n",
       "  'document': 'Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf'},\n",
       " {'page': 1,\n",
       "  'document': 'Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "display(texts[:5])\n",
    "display(metadatas[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now finally at the point where we can embed and then upload our chunks. We use the `from_texts` method on our `textbook_vector_store`, passing through our `texts`, `embedding_model`, `metadatas`, and `index_name`. Suprisingly, due to the amazing power and abstraction given to us by Langchain, this one line of code embeds and uploads all 2285 chunks of our textbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x11a25f0d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textbook_vector_store.from_texts(\n",
    "    texts=texts,\n",
    "    embedding=embedding_model,\n",
    "    metadatas=metadatas,\n",
    "    index_name=\"textbook-vector-store\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly make a function to conduct a similarity search on the vector store with respect to a user query we enter, setting the number of items to retrieve (k) to 5, printing out the retrieved context chunk and the corresponding page number and source document metadata. We use the `similarity_search` method on our `textbook_vector_store`, passing through our query and k number as parameters, loop through the results, and print the relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_display(query, k=5):\n",
    "    results = textbook_vector_store.similarity_search(query=query, k=k)\n",
    "    for result in results:\n",
    "        print(f\"Text: {result.page_content}\\n\")\n",
    "        print(f\"Document: {result.metadata['document']}\\n\")\n",
    "        print(f\"Page: {int(result.metadata['page'])}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Look at that, we see the context which was retrieved, which is by default ordered by descending with respect to the cosine similarity between the chunk and the user query, in addition to the name of the source document of that chunk and the page number from which the chunk came from so we can always cross-check the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: neural networks so that they can do something useful.\n",
      "The question we need to think about ﬁrst is how our neurons can learn. We are going to\n",
      "look atsupervised learning for the next few chapters, which means that the algorithms will\n",
      "learn by example: the dataset that we learn from has the correct output values associated\n",
      "with each datapoint. At ﬁrst sight this might seem pointless, since if you already know the\n",
      "\n",
      "Document: Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf\n",
      "\n",
      "Page: 64\n",
      "\n",
      "\n",
      "Text: a well-known introduction to neural networks:\n",
      "•D.E. Rumelhart, G.E. Hinton, and R.J. Williams. Learning internal representations\n",
      "by back-propagating errors. Nature, 323(99):533–536, 1986a.\n",
      "•D.E. Rumelhart, J.L. McClelland, and the PDP Research Group, editors. Parallel\n",
      "Distributed Processing . MIT Press, Cambridge, MA, 1986b.\n",
      "•R. Lippmann. An introduction to computing with neural nets. IEEE ASSP Magazine ,\n",
      "pages 4–22, 1987.\n",
      "\n",
      "Document: Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf\n",
      "\n",
      "Page: 129\n",
      "\n",
      "\n",
      "Text: to look at the neural network solution proposed by Rumelhart, Hinton, and McClelland,\n",
      "the Multi-layer Perceptron (MLP), which is still one of the most commonly used machine\n",
      "learning methods around. The MLP is one of the most common neural networks in use. It\n",
      "is often treated as a ‘black box’, in that people use it without understanding how it works,\n",
      "which often results in fairly poor results. Getting to the stage where we understand how it\n",
      "\n",
      "Document: Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf\n",
      "\n",
      "Page: 94\n",
      "\n",
      "\n",
      "Text: 3.2 NEURAL NETWORKS\n",
      "One thing that is probably fairly obvious is that one neuron isn’t that interesting. It doesn’t\n",
      "do very much, except ﬁre or not ﬁre when we give it inputs. In fact, it doesn’t even learn.\n",
      "If we feed in the same set of inputs over and over again, the output of the neuron never\n",
      "varies—it either ﬁres or does not. So to make the neuron a little more interesting we need\n",
      "to work out how to make it learn, and then we need to put sets of neurons together into\n",
      "\n",
      "Document: Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf\n",
      "\n",
      "Page: 64\n",
      "\n",
      "\n",
      "Text: In terms of learning about a set of data we have now reached the stage that neural\n",
      "networks were up to in 1969. Then, two researchers, Minsky and Papert, published a book\n",
      "called “Perceptrons.” The purpose of the book was to stimulate neural network research\n",
      "by discussing the learning capabilities of the Perceptron, and showing what the network\n",
      "could and could not learn. Unfortunately, the book had another eﬀect: it eﬀectively killed\n",
      "\n",
      "Document: Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf\n",
      "\n",
      "Page: 76\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrieve_and_display(\"tell me about neural networks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lastly, let's just put this into a function, to make it easy to load, process, & upload different documents a bit more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First let's do our imports and define the two global variables we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    \n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings()\n",
    "textbook_vector_store = PineconeVectorStore.from_existing_index(embedding=embedding_model, index_name=\"textbook-vector-store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_textbook_to_vector_store():\n",
    "    pdf_loader = PyPDFLoader(\"Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50, length_function=len)\n",
    "    \n",
    "    chunks = pdf_loader.load_and_split(text_splitter=text_splitter)\n",
    "    \n",
    "    texts = [chunk.page_content for chunk in chunks]\n",
    "    metadatas = [{'page': chunk.metadata['page'] + 1, 'document': chunk.metadata['source']} for chunk in chunks]\n",
    "    \n",
    "    textbook_vector_store.from_texts(\n",
    "        texts=texts,\n",
    "        embedding=embedding_model,\n",
    "        metadatas=metadatas,\n",
    "        index_name=\"textbook-vector-store\"\n",
    "    )\n",
    "    print(f\"Sucessfully Uploaded {len(texts)} Texts & {len(metadatas)} Metadatas to the Pinecone Textbook Vector Store.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_textbook_to_vector_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Exercise: Try this on your own documents, notes or textbooks. Additionally, see if you can get it to work with Langchain's `PyPDFDirectoryLoader`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wonderful, we can see everything is working as expected. It's now time to move onto the next part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Creating the RAG Component\n",
    "\n",
    "Now, that we have gone through the process of loading, splitting, embedding and uploading our textbook to the vector database, and confirmed it's working as expected, it's time to connect this system up to a language model, so we can create our Question-Answering RAG Assistant.\n",
    "\n",
    "Like before, let's inspect our imports to make sure we understand the tools we'll be using. Our first import from the `langchain_openai` integration, where we import the `ChatOpenAI` module. Our second import is from the `langchain_core` parent module, where we specifically capture the `prompts` sub-module in which we import the `ChatPromptTemplate` class.\n",
    "\n",
    "We covered the `HuggingFaceEmbeddings` and `PineconeVectorStore` imports previously, so we won't worry about covering it here again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to create our prompt template. The `ChatPromptTemplate` class provides a variety of flexible prompt templates which accommodates to various situations. When using the `ChatOpenAI` module, its most common to use the `from_messages` method, which formats system messages, human messages, and AI messages in an easy-to-understand list format which OpenAI LLM's expect.\n",
    "\n",
    "We set a pretty specific system message, making sure to instruct the LLM to answer the users question only using the provided context, and if the context doesn't contain the answer, to let the user know this, instead of just hallucinating a response. We also, just pass through a `context` and `query` variable, which will get filled in with information at run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Using ONLY the provided context, answer the user's query. If the provided context doesn't contain the answer, then return 'I don't have enough information to accurately answer the question.'\"),\n",
    "    (\"system\", \"Context: {context}\"),\n",
    "    (\"human\", \"User Query: {query}\"),\n",
    "    (\"ai\", \"Answer:\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we simply setup our inference model, in this case setting a `llm` variable to a `ChatOpenAI()` model, passing through our model name, tempature, max tokens, and timeout. There are many, many more parameters you can pass in here to customize your model, but this simple setup covers pretty much all the essentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.3,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a mechanism to capture a user query, saving it to a variable `user_query`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = input(\"Please Enter Your Query: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we defined the embedding model and vector store variables earlier, since we are going to want this section to be independent to the last section, we will redefine them here for clarification. Its helpful to think of the earlier part as the \"Document Processing & Uploading Pipeline\" and this section as the \"Query, Retrieve, & Generate Pipeline\".\n",
    "\n",
    "Each should work independently, as we may want upload many, many more textbooks in the future, but the mechanism to query that vector store and generate a response will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings()\n",
    "textbook_vector_store = PineconeVectorStore.from_existing_index(embedding=embedding_model, index_name=\"textbook-vector-store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, just like before, we'll use the `similarity_search` method on out vector store to conduct a similarity search with respect to the user query, passing through a k value of 10 instead of 5 to improve the RAG performance and reliability of the system. We will set the retrieved context to a `retrieved_contexts` variable.\n",
    "\n",
    "Inspecting the format of the retrieved context, we see its in the same format as earlier. We need to loop through all the retrieved context, parsing and extracting the page_content to a context list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='neural networks so that they can do something useful.\\nThe question we need to think about ﬁrst is how our neurons can learn. We are going to\\nlook atsupervised learning for the next few chapters, which means that the algorithms will\\nlearn by example: the dataset that we learn from has the correct output values associated\\nwith each datapoint. At ﬁrst sight this might seem pointless, since if you already know the', metadata={'document': 'Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf', 'page': 64.0}),\n",
       " Document(page_content='a well-known introduction to neural networks:\\n•D.E. Rumelhart, G.E. Hinton, and R.J. Williams. Learning internal representations\\nby back-propagating errors. Nature, 323(99):533–536, 1986a.\\n•D.E. Rumelhart, J.L. McClelland, and the PDP Research Group, editors. Parallel\\nDistributed Processing . MIT Press, Cambridge, MA, 1986b.\\n•R. Lippmann. An introduction to computing with neural nets. IEEE ASSP Magazine ,\\npages 4–22, 1987.', metadata={'document': 'Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf', 'page': 129.0}),\n",
       " Document(page_content='to look at the neural network solution proposed by Rumelhart, Hinton, and McClelland,\\nthe Multi-layer Perceptron (MLP), which is still one of the most commonly used machine\\nlearning methods around. The MLP is one of the most common neural networks in use. It\\nis often treated as a ‘black box’, in that people use it without understanding how it works,\\nwhich often results in fairly poor results. Getting to the stage where we understand how it', metadata={'document': 'Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf', 'page': 94.0}),\n",
       " Document(page_content='3.2 NEURAL NETWORKS\\nOne thing that is probably fairly obvious is that one neuron isn’t that interesting. It doesn’t\\ndo very much, except ﬁre or not ﬁre when we give it inputs. In fact, it doesn’t even learn.\\nIf we feed in the same set of inputs over and over again, the output of the neuron never\\nvaries—it either ﬁres or does not. So to make the neuron a little more interesting we need\\nto work out how to make it learn, and then we need to put sets of neurons together into', metadata={'document': 'Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf', 'page': 64.0}),\n",
       " Document(page_content='In terms of learning about a set of data we have now reached the stage that neural\\nnetworks were up to in 1969. Then, two researchers, Minsky and Papert, published a book\\ncalled “Perceptrons.” The purpose of the book was to stimulate neural network research\\nby discussing the learning capabilities of the Perceptron, and showing what the network\\ncould and could not learn. Unfortunately, the book had another eﬀect: it eﬀectively killed', metadata={'document': 'Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf', 'page': 76.0}),\n",
       " Document(page_content='The Multi-layer Perceptron ■89\\n4.4 EXAMPLES OF USING THE MLP\\nThis section is intended to be practical, so you should follow the examples at a computer,\\nand add to them as you wish. The MLP is rather too complicated to enable us to work\\nthrough the weight changes as we did with the Perceptron.\\nInstead, we shall look at some demonstrations of how to make the network learn about\\nsome data. As was mentioned above, we shall look at the four types of problems that are', metadata={'document': 'Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf', 'page': 110.0}),\n",
       " Document(page_content='The example we are going to use is something very simple that you already know about,\\nthe logical OR. This obviously isn’t something that you actually need a neural network to\\nlearn about, but it does make a nice simple example. So what will our neural network look\\nlike? There are two input nodes (plus the bias input) and there will be one output. The\\ninputs and the target are given in the table on the left of Figure 3.4; the right of the ﬁgure', metadata={'document': 'Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf', 'page': 69.0}),\n",
       " Document(page_content='Books that cover the area include:\\n•Section 10.14 of R.O. Duda, P.E. Hart, and D.G. Stork. Pattern Classiﬁcation , 2nd\\nedition, Wiley-Interscience, New York, USA, 2001.\\n•Chapter 9 of S. Haykin. Neural Networks: A Comprehensive Foundation , 2nd edition,\\nPrentice-Hall, New Jersey, USA, 1999.\\n•Section 9.3 of B.D. Ripley. Pattern Recognition and Neural Networks . Cambridge\\nUniversity Press, Cambridge, UK, 1996.\\nPRACTICE QUESTIONS', metadata={'document': 'Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf', 'page': 324.0}),\n",
       " Document(page_content='44■Machine Learning: An Algorithmic Perspective\\nFIGURE 3.2 The Perceptron network, consisting of a set of input nodes (left) connected\\nto McCulloch and Pitts neurons using weighted connections.\\ninto the network, and how many of these input values there are (which is the dimension\\n(number of elements) in the input vector). They are almost always drawn as circles, just\\nlike neurons, which is rather confusing, so I’ve shaded them a diﬀerent colour. The neurons', metadata={'document': 'Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf', 'page': 65.0}),\n",
       " Document(page_content='Learning , 2nd edition, Springer, Berlin, Germany, 2008.\\nOther texts that provide alternative views of similar material include:\\n•Chapter 1 of R.O. Duda, P.E. Hart, and D.G. Stork. Pattern Classiﬁcation , 2nd\\nedition, Wiley-Interscience, New York, USA, 2001.\\n•Chapter 1 of S. Haykin. Neural Networks: A Comprehensive Foundation , 2nd edition,\\nPrentice-Hall, New Jersey, USA, 1999.', metadata={'document': 'Machine Learning - An Algorithmic Perspective, Second Edition, by Stephen Marsland.pdf', 'page': 34.0})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_contexts = textbook_vector_store.similarity_search(query=user_query, k=10)\n",
    "retrieved_contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's exactly what we do here. We simply loop through each doc in `retrieved_contexts` and using a list comprehension, extract the parsed context to a new context list.\n",
    "\n",
    "Looking at the context list, this looks much cleaner now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neural networks so that they can do something useful.\\nThe question we need to think about ﬁrst is how our neurons can learn. We are going to\\nlook atsupervised learning for the next few chapters, which means that the algorithms will\\nlearn by example: the dataset that we learn from has the correct output values associated\\nwith each datapoint. At ﬁrst sight this might seem pointless, since if you already know the',\n",
       " 'a well-known introduction to neural networks:\\n•D.E. Rumelhart, G.E. Hinton, and R.J. Williams. Learning internal representations\\nby back-propagating errors. Nature, 323(99):533–536, 1986a.\\n•D.E. Rumelhart, J.L. McClelland, and the PDP Research Group, editors. Parallel\\nDistributed Processing . MIT Press, Cambridge, MA, 1986b.\\n•R. Lippmann. An introduction to computing with neural nets. IEEE ASSP Magazine ,\\npages 4–22, 1987.',\n",
       " 'to look at the neural network solution proposed by Rumelhart, Hinton, and McClelland,\\nthe Multi-layer Perceptron (MLP), which is still one of the most commonly used machine\\nlearning methods around. The MLP is one of the most common neural networks in use. It\\nis often treated as a ‘black box’, in that people use it without understanding how it works,\\nwhich often results in fairly poor results. Getting to the stage where we understand how it',\n",
       " '3.2 NEURAL NETWORKS\\nOne thing that is probably fairly obvious is that one neuron isn’t that interesting. It doesn’t\\ndo very much, except ﬁre or not ﬁre when we give it inputs. In fact, it doesn’t even learn.\\nIf we feed in the same set of inputs over and over again, the output of the neuron never\\nvaries—it either ﬁres or does not. So to make the neuron a little more interesting we need\\nto work out how to make it learn, and then we need to put sets of neurons together into',\n",
       " 'In terms of learning about a set of data we have now reached the stage that neural\\nnetworks were up to in 1969. Then, two researchers, Minsky and Papert, published a book\\ncalled “Perceptrons.” The purpose of the book was to stimulate neural network research\\nby discussing the learning capabilities of the Perceptron, and showing what the network\\ncould and could not learn. Unfortunately, the book had another eﬀect: it eﬀectively killed',\n",
       " 'The Multi-layer Perceptron ■89\\n4.4 EXAMPLES OF USING THE MLP\\nThis section is intended to be practical, so you should follow the examples at a computer,\\nand add to them as you wish. The MLP is rather too complicated to enable us to work\\nthrough the weight changes as we did with the Perceptron.\\nInstead, we shall look at some demonstrations of how to make the network learn about\\nsome data. As was mentioned above, we shall look at the four types of problems that are',\n",
       " 'The example we are going to use is something very simple that you already know about,\\nthe logical OR. This obviously isn’t something that you actually need a neural network to\\nlearn about, but it does make a nice simple example. So what will our neural network look\\nlike? There are two input nodes (plus the bias input) and there will be one output. The\\ninputs and the target are given in the table on the left of Figure 3.4; the right of the ﬁgure',\n",
       " 'Books that cover the area include:\\n•Section 10.14 of R.O. Duda, P.E. Hart, and D.G. Stork. Pattern Classiﬁcation , 2nd\\nedition, Wiley-Interscience, New York, USA, 2001.\\n•Chapter 9 of S. Haykin. Neural Networks: A Comprehensive Foundation , 2nd edition,\\nPrentice-Hall, New Jersey, USA, 1999.\\n•Section 9.3 of B.D. Ripley. Pattern Recognition and Neural Networks . Cambridge\\nUniversity Press, Cambridge, UK, 1996.\\nPRACTICE QUESTIONS',\n",
       " '44■Machine Learning: An Algorithmic Perspective\\nFIGURE 3.2 The Perceptron network, consisting of a set of input nodes (left) connected\\nto McCulloch and Pitts neurons using weighted connections.\\ninto the network, and how many of these input values there are (which is the dimension\\n(number of elements) in the input vector). They are almost always drawn as circles, just\\nlike neurons, which is rather confusing, so I’ve shaded them a diﬀerent colour. The neurons',\n",
       " 'Learning , 2nd edition, Springer, Berlin, Germany, 2008.\\nOther texts that provide alternative views of similar material include:\\n•Chapter 1 of R.O. Duda, P.E. Hart, and D.G. Stork. Pattern Classiﬁcation , 2nd\\nedition, Wiley-Interscience, New York, USA, 2001.\\n•Chapter 1 of S. Haykin. Neural Networks: A Comprehensive Foundation , 2nd edition,\\nPrentice-Hall, New Jersey, USA, 1999.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = [doc.page_content for doc in retrieved_contexts]\n",
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the user query and the context, we are ready to populate our prompt template with these values. So using the `invoke` method on our template, we pass through our `user_query` and `context` variables through to their respective key.\n",
    "\n",
    "We set this finalized prompt to the `prompt_value` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "prompt_value = template.invoke({\n",
    "    \"query\": user_query,\n",
    "    \"context\": context\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, that our prompt template has been populated, we are ready to pass through our prompt to the LLM using the `invoke` method on our `llm`, passing through our `prompt_value` which contains our prompt. We capture the response in the `response` variable, and print out the response.\n",
    "\n",
    "Wow! Look at that. We got the response from the LLM, we just need to parse the content of the response and then we have for all intents and purposes created a RAG Pipeline in Langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Neural networks are computational models inspired by the human brain, consisting of interconnected nodes (neurons) that process information. They can learn from data, particularly through supervised learning, where the dataset includes correct output values for each data point. One common type of neural network is the Multi-layer Perceptron (MLP), which is widely used in machine learning. Neural networks can solve various problems, but understanding how they work is crucial to avoid poor results. Key references in the field include works by Rumelhart, Hinton, McClelland, and others.', response_metadata={'token_usage': {'completion_tokens': 115, 'prompt_tokens': 1209, 'total_tokens': 1324}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_ce0793330f', 'finish_reason': 'stop', 'logprobs': None}, id='run-33481a60-d27e-4cb7-8c6d-e1dc0651a448-0', usage_metadata={'input_tokens': 1209, 'output_tokens': 115, 'total_tokens': 1324})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke(prompt_value)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting out the content, we get our final response from the LLM which is now our question answered using only chunks of retrieved context which we have just uploaded a few minutes prior. Beautiful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neural networks are computational models inspired by the human brain, consisting of interconnected nodes (neurons) that process information. They can learn from data, particularly through supervised learning, where the dataset includes correct output values for each data point. One common type of neural network is the Multi-layer Perceptron (MLP), which is widely used in machine learning. Neural networks can solve various problems, but understanding how they work is crucial to avoid poor results. Key references in the field include works by Rumelhart, Hinton, McClelland, and others.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_response = response.content\n",
    "parsed_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a bit of fun, let's inspect the prompt actually sent to the model...\n",
    "\n",
    "Oh, that's not very helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content=\"Using ONLY the provided context, answer the user's query. If the provided context doesn't contain the answer, then return 'I don't have enough information to accurately answer the question.'\"), SystemMessage(content=\"Context: ['neural networks so that they can do something useful.\\\\nThe question we need to think about ﬁrst is how our neurons can learn. We are going to\\\\nlook atsupervised learning for the next few chapters, which means that the algorithms will\\\\nlearn by example: the dataset that we learn from has the correct output values associated\\\\nwith each datapoint. At ﬁrst sight this might seem pointless, since if you already know the', 'a well-known introduction to neural networks:\\\\n•D.E. Rumelhart, G.E. Hinton, and R.J. Williams. Learning internal representations\\\\nby back-propagating errors. Nature, 323(99):533–536, 1986a.\\\\n•D.E. Rumelhart, J.L. McClelland, and the PDP Research Group, editors. Parallel\\\\nDistributed Processing . MIT Press, Cambridge, MA, 1986b.\\\\n•R. Lippmann. An introduction to computing with neural nets. IEEE ASSP Magazine ,\\\\npages 4–22, 1987.', 'to look at the neural network solution proposed by Rumelhart, Hinton, and McClelland,\\\\nthe Multi-layer Perceptron (MLP), which is still one of the most commonly used machine\\\\nlearning methods around. The MLP is one of the most common neural networks in use. It\\\\nis often treated as a ‘black box’, in that people use it without understanding how it works,\\\\nwhich often results in fairly poor results. Getting to the stage where we understand how it', '3.2 NEURAL NETWORKS\\\\nOne thing that is probably fairly obvious is that one neuron isn’t that interesting. It doesn’t\\\\ndo very much, except ﬁre or not ﬁre when we give it inputs. In fact, it doesn’t even learn.\\\\nIf we feed in the same set of inputs over and over again, the output of the neuron never\\\\nvaries—it either ﬁres or does not. So to make the neuron a little more interesting we need\\\\nto work out how to make it learn, and then we need to put sets of neurons together into', 'In terms of learning about a set of data we have now reached the stage that neural\\\\nnetworks were up to in 1969. Then, two researchers, Minsky and Papert, published a book\\\\ncalled “Perceptrons.” The purpose of the book was to stimulate neural network research\\\\nby discussing the learning capabilities of the Perceptron, and showing what the network\\\\ncould and could not learn. Unfortunately, the book had another eﬀect: it eﬀectively killed', 'The Multi-layer Perceptron ■89\\\\n4.4 EXAMPLES OF USING THE MLP\\\\nThis section is intended to be practical, so you should follow the examples at a computer,\\\\nand add to them as you wish. The MLP is rather too complicated to enable us to work\\\\nthrough the weight changes as we did with the Perceptron.\\\\nInstead, we shall look at some demonstrations of how to make the network learn about\\\\nsome data. As was mentioned above, we shall look at the four types of problems that are', 'The example we are going to use is something very simple that you already know about,\\\\nthe logical OR. This obviously isn’t something that you actually need a neural network to\\\\nlearn about, but it does make a nice simple example. So what will our neural network look\\\\nlike? There are two input nodes (plus the bias input) and there will be one output. The\\\\ninputs and the target are given in the table on the left of Figure 3.4; the right of the ﬁgure', 'Books that cover the area include:\\\\n•Section 10.14 of R.O. Duda, P.E. Hart, and D.G. Stork. Pattern Classiﬁcation , 2nd\\\\nedition, Wiley-Interscience, New York, USA, 2001.\\\\n•Chapter 9 of S. Haykin. Neural Networks: A Comprehensive Foundation , 2nd edition,\\\\nPrentice-Hall, New Jersey, USA, 1999.\\\\n•Section 9.3 of B.D. Ripley. Pattern Recognition and Neural Networks . Cambridge\\\\nUniversity Press, Cambridge, UK, 1996.\\\\nPRACTICE QUESTIONS', '44■Machine Learning: An Algorithmic Perspective\\\\nFIGURE 3.2 The Perceptron network, consisting of a set of input nodes (left) connected\\\\nto McCulloch and Pitts neurons using weighted connections.\\\\ninto the network, and how many of these input values there are (which is the dimension\\\\n(number of elements) in the input vector). They are almost always drawn as circles, just\\\\nlike neurons, which is rather confusing, so I’ve shaded them a diﬀerent colour. The neurons', 'Learning , 2nd edition, Springer, Berlin, Germany, 2008.\\\\nOther texts that provide alternative views of similar material include:\\\\n•Chapter 1 of R.O. Duda, P.E. Hart, and D.G. Stork. Pattern Classiﬁcation , 2nd\\\\nedition, Wiley-Interscience, New York, USA, 2001.\\\\n•Chapter 1 of S. Haykin. Neural Networks: A Comprehensive Foundation , 2nd edition,\\\\nPrentice-Hall, New Jersey, USA, 1999.']\"), HumanMessage(content='User Query: tell me about neural networks'), AIMessage(content='Answer:')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's parse this so it looks a bit nicer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = prompt_value.messages\n",
    "\n",
    "system_instructions = messages[0].content\n",
    "context_message = messages[1].content\n",
    "user_query_message = messages[2].content\n",
    "llm_response = parsed_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM INSTRUCTIONS:\n",
      "Using ONLY the provided context, answer the user's query. If the provided context doesn't contain the answer, then return 'I don't have enough information to accurately answer the question.'\n",
      "CONTEXT SENT TO MODEL:\n",
      "Context: ['neural networks so that they can do something useful.\\nThe question we need to think about ﬁrst is how our neurons can learn. We are going to\\nlook atsupervised learning for the next few chapters, which means that the algorithms will\\nlearn by example: the dataset that we learn from has the correct output values associated\\nwith each datapoint. At ﬁrst sight this might seem pointless, since if you already know the', 'a well-known introduction to neural networks:\\n•D.E. Rumelhart, G.E. Hinton, and R.J. Williams. Learning internal representations\\nby back-propagating errors. Nature, 323(99):533–536, 1986a.\\n•D.E. Rumelhart, J.L. McClelland, and the PDP Research Group, editors. Parallel\\nDistributed Processing . MIT Press, Cambridge, MA, 1986b.\\n•R. Lippmann. An introduction to computing with neural nets. IEEE ASSP Magazine ,\\npages 4–22, 1987.', 'to look at the neural network solution proposed by Rumelhart, Hinton, and McClelland,\\nthe Multi-layer Perceptron (MLP), which is still one of the most commonly used machine\\nlearning methods around. The MLP is one of the most common neural networks in use. It\\nis often treated as a ‘black box’, in that people use it without understanding how it works,\\nwhich often results in fairly poor results. Getting to the stage where we understand how it', '3.2 NEURAL NETWORKS\\nOne thing that is probably fairly obvious is that one neuron isn’t that interesting. It doesn’t\\ndo very much, except ﬁre or not ﬁre when we give it inputs. In fact, it doesn’t even learn.\\nIf we feed in the same set of inputs over and over again, the output of the neuron never\\nvaries—it either ﬁres or does not. So to make the neuron a little more interesting we need\\nto work out how to make it learn, and then we need to put sets of neurons together into', 'In terms of learning about a set of data we have now reached the stage that neural\\nnetworks were up to in 1969. Then, two researchers, Minsky and Papert, published a book\\ncalled “Perceptrons.” The purpose of the book was to stimulate neural network research\\nby discussing the learning capabilities of the Perceptron, and showing what the network\\ncould and could not learn. Unfortunately, the book had another eﬀect: it eﬀectively killed', 'The Multi-layer Perceptron ■89\\n4.4 EXAMPLES OF USING THE MLP\\nThis section is intended to be practical, so you should follow the examples at a computer,\\nand add to them as you wish. The MLP is rather too complicated to enable us to work\\nthrough the weight changes as we did with the Perceptron.\\nInstead, we shall look at some demonstrations of how to make the network learn about\\nsome data. As was mentioned above, we shall look at the four types of problems that are', 'The example we are going to use is something very simple that you already know about,\\nthe logical OR. This obviously isn’t something that you actually need a neural network to\\nlearn about, but it does make a nice simple example. So what will our neural network look\\nlike? There are two input nodes (plus the bias input) and there will be one output. The\\ninputs and the target are given in the table on the left of Figure 3.4; the right of the ﬁgure', 'Books that cover the area include:\\n•Section 10.14 of R.O. Duda, P.E. Hart, and D.G. Stork. Pattern Classiﬁcation , 2nd\\nedition, Wiley-Interscience, New York, USA, 2001.\\n•Chapter 9 of S. Haykin. Neural Networks: A Comprehensive Foundation , 2nd edition,\\nPrentice-Hall, New Jersey, USA, 1999.\\n•Section 9.3 of B.D. Ripley. Pattern Recognition and Neural Networks . Cambridge\\nUniversity Press, Cambridge, UK, 1996.\\nPRACTICE QUESTIONS', '44■Machine Learning: An Algorithmic Perspective\\nFIGURE 3.2 The Perceptron network, consisting of a set of input nodes (left) connected\\nto McCulloch and Pitts neurons using weighted connections.\\ninto the network, and how many of these input values there are (which is the dimension\\n(number of elements) in the input vector). They are almost always drawn as circles, just\\nlike neurons, which is rather confusing, so I’ve shaded them a diﬀerent colour. The neurons', 'Learning , 2nd edition, Springer, Berlin, Germany, 2008.\\nOther texts that provide alternative views of similar material include:\\n•Chapter 1 of R.O. Duda, P.E. Hart, and D.G. Stork. Pattern Classiﬁcation , 2nd\\nedition, Wiley-Interscience, New York, USA, 2001.\\n•Chapter 1 of S. Haykin. Neural Networks: A Comprehensive Foundation , 2nd edition,\\nPrentice-Hall, New Jersey, USA, 1999.']\n",
      "ENTERED USER QUERY:\n",
      "User Query: tell me about neural networks\n",
      "RESPONSE FROM LLM:\n",
      "Neural networks are computational models inspired by the human brain, consisting of interconnected nodes (neurons) that process information. They can learn from data, particularly through supervised learning, where the dataset includes correct output values for each data point. One common type of neural network is the Multi-layer Perceptron (MLP), which is widely used in machine learning. Neural networks can solve various problems, but understanding how they work is crucial to avoid poor results. Key references in the field include works by Rumelhart, Hinton, McClelland, and others.\n"
     ]
    }
   ],
   "source": [
    "print(f\"SYSTEM INSTRUCTIONS:\\n{system_instructions}\")\n",
    "print(f\"CONTEXT SENT TO MODEL:\\n{context_message}\")\n",
    "print(f\"ENTERED USER QUERY:\\n{user_query_message}\")\n",
    "print(f\"RESPONSE FROM LLM:\\n{llm_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to put it in a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First let's do our imports and define the two global variables we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings()\n",
    "textbook_vector_store = PineconeVectorStore.from_existing_index(embedding=embedding_model, index_name=\"textbook-vector-store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textbook_rag():\n",
    "\n",
    "    user_query = input(\"Please Enter Your Query: \")\n",
    "\n",
    "    template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Using ONLY the provided context, answer the user's query. If the provided context doesn't contain the answer, then return 'I don't have enough information to accurately answer the question'\"),\n",
    "        (\"system\", \"Context: {context}\"),\n",
    "        (\"human\", \"User Query: {query}\"),\n",
    "        (\"ai\", \"Answer:\")\n",
    "    ])\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0.3,\n",
    "        max_tokens=None,\n",
    "        timeout=None,\n",
    "    )\n",
    "\n",
    "    retrieved_contexts = textbook_vector_store.similarity_search(query=user_query, k=10)\n",
    "    context = [doc.page_content for doc in retrieved_contexts]\n",
    "\n",
    "    prompt_value = template.invoke({\n",
    "        \"query\": user_query,\n",
    "        \"context\": context\n",
    "    })\n",
    "\n",
    "    response = llm.invoke(prompt_value)\n",
    "    parsed_response = response.content\n",
    "    print(parsed_response)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textbook_rag()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, we have now created a complete, albeit simple RAG implementation using only Langchain components/integrations, starting at external document loading, splitting, embedding, and uploading, and then conducting on the spot retrieval based on a user query to a GPT-4o inference model, printing out the results.\n",
    "\n",
    "Please use this notebook as a base, and in your own time, experiment by adding components, swapping out components, and creating some cool applications!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
